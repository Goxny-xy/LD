[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Hello",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nIf you find that some pages are blank, click Refresh or something else in the menu bar and then return to view them.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Week1",
    "section": "",
    "text": "##Summary\n##What is remote sensing? Remote sensing is a technique and scientific method for obtaining and analysing information about the Earth’s surface, atmosphere and oceans without direct contact with the object. The technique relies on the detection and measurement of electromagnetic radiation emitted or reflected from a target object or area. Remote sensing equipment can be mounted on different platforms, including satellites, aircraft, unmanned aerial vehicles (UAVs) and ground stations, to collect a wide range of data about the Earth. ##How it works?"
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2",
    "section": "",
    "text": "hi"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Dairy",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "2  Week1 Getting started with RS",
    "section": "2.1 Summary",
    "text": "2.1 Summary\n\n2.1.1 What is remote sensing?\nA scientific method and technique for gathering data about the Earth’s surface, atmosphere, and oceans without making physical touch with the item is called remote sensing. The method is dependent on the identification and quantification of electromagnetic radiation that is either reflected or emitted from a target area or object. A variety of platforms, including as satellites, aeroplanes, unmanned aerial vehicles (UAVs), and ground stations, can be equipped with remote sensing technology to gather a variety of data about the planet.\n\n\n\nSource：https://openclipart.org/detail/274076/cartoon-sentinel-satellites-parody\n\n\n\n\n2.1.2 How it works?\nActive remote sensing: electromagnetic waves are emitted by the sensors and are reflected back from features. For example, a radar system measures a feature’s distance, shape, roughness, and other characteristics by sending out microwaves and receiving their reply.\nPassive remote sensing: depends on the feature itself or on electromagnetic radiation released by a natural light source (like the sun). When sunlight strikes the Earth’s surface, for instance, sensors aboard satellites or aircraft catch the light reflected from features.\n\n\n\nPassive vs active. Source: https://www.researchgate.net/figure/Figure-14-Passive-and-Active-Remote-Sensing-System-16_fig2_363487937"
  },
  {
    "objectID": "week1.html#what-is-remote-sensing",
    "href": "week1.html#what-is-remote-sensing",
    "title": "1  Week1",
    "section": "1.2 What is remote sensing?",
    "text": "1.2 What is remote sensing?\nRemote sensing is a technique and scientific method for obtaining and analysing information about the Earth’s surface, atmosphere and oceans without direct contact with the object. The technique relies on the detection and measurement of electromagnetic radiation emitted or reflected from a target object or area. Remote sensing equipment can be mounted on different platforms, including satellites, aircraft, unmanned aerial vehicles (UAVs) and ground stations, to collect a wide range of data about the Earth. ##How it works?"
  },
  {
    "objectID": "week1.html#applications",
    "href": "week1.html#applications",
    "title": "2  Week1 Getting started with RS",
    "section": "2.2 Applications",
    "text": "2.2 Applications\nRemote sensing has obvious advantages in environmental monitoring, crop estimation, disaster monitoring, global change, and many more. I am most interested in disaster monitoring, especially earthquakes (because the recent film I watched with the crustal rupture sequence made me feel the need to prepare some knowledge about earthquakes).\nThis week’s study has led me to search and read a lot of articles about remote sensing applications, and I found that it is interesting and difficult to monitor small vibrations like pre-earthquakes and aftershocks. For example, in the case of the Iranian earthquake, there are at least two different ways to observe its seismicity.\nDing et al., (2018) focused on monitoring surface deformation via InSAR by comparing radar images acquired at different times, accurately measuring surface movement, and inverting slip distributions and rupture processes to detect where earthquakes are most likely to occur. While Saraf et al., (2008) used thermal infrared to detect earthquakes where they are most likely to occur by monitoring the surface temperature changes and visually analysing the thermal images, which are then analysed in detail to understand the approximate time of occurrence of thermal anomalies, the intensity of thermal rise, and its spatial extent to monitor earthquakes.\nSince Iran is part of the Alpine-Himalayan belt, it belongs to one of the most seismic regions in the world, and in addition to the high seismic activity, it has relatively cloudless and stable weather conditions for most of the year as well as sparse vegetation cover. Based on these two prerequisites, InSAR is more advantageous. Moreover, the frictional heat generated on the fault surface during rupture takes some time to reach the surface, which may make thermal infrared monitoring of earthquakes inaccurate.\nIt was also nice to discover that Liu et al., (2021) found that the optimised approach to InSAR is time series (I didn’t realise that a course I had once taken could still be applied here) because using time series analysis, it is possible to detect small co-seismic events that are not readily visible or clearly defined in a single interferogram. seen or unclear in small coseismic displacements, and to improve images of earthquakes by looking at how estimates of ground motion change over time, leading to clearer observations of earthquakes and modelling of aftershocks following large earthquakes."
  },
  {
    "objectID": "week1.html#reflections",
    "href": "week1.html#reflections",
    "title": "2  Week1 Getting started with RS",
    "section": "2.3 Reflections",
    "text": "2.3 Reflections\nLearning theoretical concepts like electromagnetic wave theory and sensor principles is only one aspect of studying remote sensing technology; another is actually downloading, processing, and analysing data through hands-on operations. Most importantly, remote sensing is dedicated to finding workable solutions, which makes me feel that it has value in the social, environmental, and economic domains. It even makes me consider the satisfaction of using what I have learned to truly assist in problem solving—something I may do in the future."
  },
  {
    "objectID": "week2.html#summary",
    "href": "week2.html#summary",
    "title": "2  Week 2",
    "section": "2.1 Summary",
    "text": "2.1 Summary"
  },
  {
    "objectID": "week2.html#applications",
    "href": "week2.html#applications",
    "title": "2  Week 2",
    "section": "2.2 Applications",
    "text": "2.2 Applications"
  },
  {
    "objectID": "week2.html#reflections",
    "href": "week2.html#reflections",
    "title": "2  Week 2",
    "section": "2.3 Reflections",
    "text": "2.3 Reflections"
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "5  Week4 Policy：Flood management policy - San José",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nBecause of its location in the Convergence Zone, Costa Rica is frequently affected by stormy weather and has limited chances of recovering from such tropical weather events, which is why extreme flooding is a frequent occurrence there.\nThe “Green Cities” policy was developed to reduce the impact of flooding, reduce the risk to human life, property and livelihoods, and promote faster recovery by identifying vulnerable zones, such as flood-prone areas, and analysing which areas of the city are susceptible to damage to the natural ecology, thereby facilitating coordination between technical agencies, the Red Cross and local governments. recovery. The development policy will focus on improving the capital, San José.\n\n\n\nCommunities flooded in Caño Ciego. Source: https://www.scielo.sa.cr/scielo.php?pid=S2215-25632023000100273&script=sci_arttext&tlng=en."
  },
  {
    "objectID": "week4.html#applications",
    "href": "week4.html#applications",
    "title": "5  Week4 Policy：Flood management policy - San José",
    "section": "5.2 Applications",
    "text": "5.2 Applications\nEffective flood management requires a good understanding of historical flooding trends, future expectations, and identification of locations likely to be affected by flooding.\nI believe that open source remote sensing data can be used to first model floods for developing areas like what Ekeu-wei and Blackburn (2018) have done and can provide a baseline for subsequent work to ensure effective preparation, response and recovery to mitigate the impacts of floods.\nFor example the HYPE (Hydrological Predictions for the Environment) model of rainfall runoff in Costa Rican areas studied by Arciniega-Esparza et al. (2022) can be used to quantitatively assess the hydrological characteristics of Costa Rica on a national scale for the purpose of identifying intra-urban flooding The aim is to identify flood-prone areas within the city.\nImprovements in the model can be achieved by incorporating more independent data into the calibration process, such as soil moisture and groundwater levels, as well as storage data. In cases of data scarcity due to policy and national circumstances, data scarcity can be compensated for by forcing, calibrating and independently evaluating the model using adapted global topography and remotely sensed climate products.\nIn the future, such large-scale hydrological models have the potential for practical application throughout the humid tropics to inform decision-making at a relatively high spatial and temporal resolution."
  },
  {
    "objectID": "week4.html#reflections",
    "href": "week4.html#reflections",
    "title": "5  Week4 Policy：Flood management policy - San José",
    "section": "5.3 Reflections",
    "text": "5.3 Reflections\nBy attempting to use knowledge of remote sensing to address flood prevention policies in San Jose, I have learnt about the use of remote sensing technologies in disaster risk management. These technologies provide accurate topographic, climatic, and hydrological data, which are essential for predicting flood events and developing effective responses, as well as further improving the accuracy and efficiency of flood predictions.\nThe case of San Jose taught me that effective flood management is not just a technical issue, but also a policy and social issue. As flood modelling and mapping typically requires flood frequency estimation, hydrodynamic modelling and flood mapping, these require specific datasets that are often unavailable in developing regions because of financial, logistical, technical and organisational policy challenges. I realised that open datasets are urgent and important for flood analysis in developing regions.\nThrough this learning experience, I gained insight into the interplay of policy, urban planning and data applications in disaster risk management. Effective flood management strategies require interdisciplinary collaboration that combines policy making, urban planning, and data science and technology to respond to flood hazards in a scientific and systematic way that promotes the sustainable development of San José, and even extends to other similar cities in the humid tropics!"
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "4  Week3 Corrections",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\n4.1.1 Atmosphereic correction\n\n4.1.1.1 Dark Object Subtraction (DOS)\nThe dark subtraction processor implements a simple empirical “atmospheric correction” method of calculation for the source product. This method searches for the darkest pixel value in each band and removes the scattering by subtracting that value from each pixel in the band, thus correcting the original satellite (or any other) image.\nIt is assumed that the darkest parts of the image (water, man-made structures) should be black if there is no effect of atmospheric scattering. A correction is made so that the black value of one band can be used to correct the remaining bands.\n\n\n\n4.1.2 enhancement\n\n4.1.2.1 Ratio: Normalised Difference Vegetation Index NDVI\nIt is a simple graphical metric commonly used to analyse remotely sensed measurements and to assess whether an observation target contains green and healthy vegetation. It quantifies vegetation based on measuring the difference between near-infrared (NIR), which is strongly reflected by vegetation, and red light, which is absorbed by vegetation/has low reflectivity. It’s calculated as follows:\nThe NDVI values range between -1 and 1, and will increase proportionally with vegetation growth. (An area without any growth will have an NDVI of zero.) An area with dense, healthy vegetation will have an NDVI of 1. An area with dense, healthy vegetation will have an NDVI of 1. An NDVI value of less than 0 indicates a lack of drylands. The NDVI of the ocean will be -1.)\n\n\n\nThe example of how to calculate NDVI. Source: NDVI from First Principles\n\n\nTherefore, it can also be said that NDVI is an indicator of the health of green vegetation. Its accuracy and high correlation with the real state of the ground vegetation is very popular.\n\n\n\n4.1.3 Texture\nTexture is one of the most important features in the process of image interpretation and classification. Compared to other important spatial features (e.g., shape and size), it is relatively simple to use because it does not require prior image segmentation. In the lecture we learned about the use of grey scale covariance matrices (GLCM) to look at features in different regions.\n\n\n\nThe Comparison of Different Methods of Texture Analysis for Their Efficacy for Land Use Classification in Satellite Imagery (Kupidura 2019).\n\n\n\n\n4.1.4 PCA\nPCA is used to remove redundant spectral information from multi-band datasets and is therefore a form of dimensionality reduction. We can specify whether to perform normalised PCA and the number of output components to be generated (all components will be output unless otherwise specified)."
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "4  Week3 Corrections",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nOcean colour (OC) remote sensing is important for monitoring marine ecosystems. However, inversion of OC signals from top-of-atmosphere (TOA) radiance measured by satellite sensors remains a challenge because the inversion accuracy is highly dependent on the performance of atmospheric corrections and sensor calibration.\nIt has been studied that the performance of dark target subtraction is satisfactory for coastal and inland water applications of Landsat TM and SeaWiFS (Shanmugam and Ahn 2007). However, it is worth noting that this method’s ability to retrieve land surface reflectance properties with high accuracy is problematic for accurate atmospheric correction of satellite ocean colour images of aquatic environments. This is because the surface reflectance usually does not contain information about the water column. The residual radiance signal from the water column accounts for only 10-20 per cent of the TOA signal, which is much smaller than the contribution of surface reflected light to the TOA signal. While, Ilori, Pahlevan and Knudby (2019) found, by comparing estimated (OLI) and observed (AERONET-OC) Rrs values, that SeaDAS compared to other atmospheric correction methods performed the best in a variety of aquatic/ atmospheric conditions with the best overall performance.\nThe discovery of the Improved Dark Object Subtraction (IDOS) method has led to a significant improvement in the visual effect, image clarity and image contrast of remote sensing images; the atmospheric-corrected reflectance curves are closer to the measured typical object reflectance curves in both spectral shapes and reflectance values, which indicates that the algorithm has successfully eliminated the atmospheric influence. Compared with the traditional DOS technique, the accuracy and practicality of the IDOS method are greatly improved (Wang et al., 2019)."
  },
  {
    "objectID": "week3.html#reflections",
    "href": "week3.html#reflections",
    "title": "4  Week3 Corrections",
    "section": "4.3 Reflections",
    "text": "4.3 Reflections\nThe study of NDVI allowed me to better understand the examples given in the first lesson of CASA0024, as well as to know what atmospheric correction is and why this operational step is so important, also helped me to understand how to remove atmospheric influences from remotely sensed imagery in order to obtain more realistic information about surface reflectance. This process is important for increasing the value of remote sensing data for applications, whether it plays an integral role in land cover classification, vegetation monitoring or environmental assessment.\nSecond, texture is an essential component of the picture that can reveal details about the surface’s composition and structure, both of which are critical for remote sensing image interpretation. Different classes can be readily detected using the texture information of the image, which can lead to more accurate work in the future.\nOverall, studying texture analysis and atmospheric correction has deepened my understanding of the use and promise of remote sensing technologies for real-world issue solving."
  },
  {
    "objectID": "week1.html#references",
    "href": "week1.html#references",
    "title": "2  Week1 Getting started with RS",
    "section": "2.4 References",
    "text": "2.4 References\nDing, K., He, P., Wen, Y., Chen, Y., Wang, D., Li, S. and Wang, Q. (2018). ‘The 2017 Mw 7.3 Ezgeleh, Iran earthquake determined from InSAR measurements and teleseismic waveforms’. Geophysical Journal International, 215 (3), pp. 1728–1738. doi: 10.1093/gji/ggy371.\nLiu, F., Elliott, J. R., Craig, T. J., Hooper, A. and Wright, T. J. (2021). ‘Improving the Resolving Power of InSAR for Earthquakes Using Time Series: A Case Study in Iran’. Geophysical Research Letters, 48 (14), p. e2021GL093043. doi: 10.1029/2021GL093043.\nSaraf, A. K., Rawat, V., Banerjee, P., Choudhury, S., Panda, S. K., Dasgupta, S. and Das, J. D. (2008). ‘Satellite detection of earthquake thermal infrared precursors in Iran’. Natural Hazards, 47 (1), pp. 119–135. doi: 10.1007/s11069-007-9201-7."
  },
  {
    "objectID": "week2.html#xaringan",
    "href": "week2.html#xaringan",
    "title": "3  Week2 Portfolio",
    "section": "3.1 Xaringan",
    "text": "3.1 Xaringan"
  },
  {
    "objectID": "week6.html#applications",
    "href": "week6.html#applications",
    "title": "6  Week6 Google Earth Engine",
    "section": "6.2 Applications",
    "text": "6.2 Applications\nGEE also includes climatic weather and geophysical data sets. Other ready-to-use products such as the Enhanced Vegetation Index (EVI) and the Normalised Difference Vegetation Index (NDVI) are also available. In addition to providing a large repository of raw remotely sensed imagery, users can access pre-processed, cloud-removed and mosaiced imagery from the GEE data catalogue.\nIn the study of land cover change, Hussain et al., (2020) first downloaded Landsat satellite images from the United States Geological Survey (USGS), and since Landsat images had to be composited, and thus also subsetted using the study area based image mask extraction tool in Arc GIS 10.1 software, the vegetation index NDVI was calculated to compare land cover changes over the years. processing, and finally the vegetation index NDVI was calculated to compare the land cover changes over the years.\nHowever, in the article studying the land cover of Beijing, Huang et al., (2017) completed the image processing steps of the previous method directly on GEE, and also calculated and exported the NDVI stack files directly.\nIt can be seen that Earth Engine does make remote sensing analyses faster and more accessible (you don’t have to download a lot of data and then spend a lot of time dealing with huge raster files), but at the same time it has to be admitted that Arc GIS operations are easier to get started with relative to GEE, and do not require programming skills."
  },
  {
    "objectID": "week6.html#reflections",
    "href": "week6.html#reflections",
    "title": "6  Week6 Google Earth Engine",
    "section": "6.3 Reflections",
    "text": "6.3 Reflections\nI’ve been shocked by the huge dataset access through this week with GEE, and the fact that there’s little to worry about in terms of data storage and processing power. And I love the advantage of fast visualisation over SNAP, the lower resolution allows me to see clearly where I want to see (it’s the download that’s a bit of a headache for me humanly…) !\nNowadays, when data is becoming more and more dense, especially with the availability of the new Sentinel series, as a user of remote sensing data, more ready-to-use options are what I’m looking for and exploring, and platforms such as GEE certainly have the advantage of working with large datasets and creating powerful visualisations, and the user-friendliness appeals to the “non-expert” user of satellite imagery. The user-friendliness appeals to “non-expert” users of satellite imagery.\nHowever, I am concerned that because GEE relies on satellite data, which may have limitations in terms of temporal coverage and weather conditions, GEE may not be applicable to all remote sensing problems."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Week6 Google Earth Engine",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n6.1.1 What is GEE?\nGoogle Earth Engine is a cloud-based geospatial analysis platform that enables users to visualize and analyse satellite images of the Earth.\nIt allows users to download and upload global satellite images and allows them to perform complex calculations on them. It consists of two main components that work in tandem with each other, namely the Google Earth Engine Explorer (EE), which is used to view datasets, and the Google Earth Engine Playground (EEP), which is used to perform JavaScript APIs for raster, vector and array operations.\n\n\n\n(a) Google Earth Engine Explorer that is an efficient data visualizer (b) Google Earth Engine Playground, which is the JavaScript API for carrying out raster, vector and array operations.\n\n\n\n\n6.1.2 GEE Architecture\nGEE is set up based on Google Cloud, the bottom layer is data storage, including 20 levels of raster and 22 levels of vector tile data; the second layer is the cloud computing layer, divided into instant response computing and batch computing; the third layer is the networked REST (Representational State Transfer) APls service; the fourth layer is the client library, which is called JavaScript API and Python API; the top layer is the interaction layer, JavaScript API corresponds to Code Editor, and Python API corresponds to the webpage or local application developed by the three parties. The fourth layer is the client library, using JavaScript and Python to parse REST APIs, which can be called JavaScript API and Python API; the top layer is the interaction layer, JavaScript API corresponds to Code Editor, and Python API corresponds to three-party development of web pages or local applications.\n\n\n\nGEE Architecture (Gomes et al. 2020)\n\n\n\n\n6.1.3 Advantages\n1.Massive multi-source data: GEE aggregates petabytes of massive geographic information spatial data, including satellite remote sensing, aerial remote sensing, basic geographic information and advanced application products that can be used directly.\n2.Superior Cloud Computing: GEE is built on the Google Cloud Services platform, which allows for parallel processing of analysis tasks and nearly unlimited computational resources, eliminating the need to consider hardware costs.\n3.Standardised user interfaces: GEE provides dual user interfaces based on JavaScript and Python languages, and standardised encapsulation of many data processing functions, which greatly reduces the learning threshold for users.\n4.Good development ecosystem: GEE has attached great importance to the development of the development ecosystem since the beginning of its launch, with rich official development documentation, the support of scientific research project funds, an active development community, and the organisation of occasional developers’ conferences, etc., which have injected strong vitality into the development of GEE."
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Week7 Classification I",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nSupervised classification is the most commonly used technique for quantitative chemical analysis of remote sensing image data. Supervised classification supports the idea that the user can select sample pixels in an image that represent a particular class, thereby instructing the image processing software to use these training sites as a reference for classifying all other pixels within the image.\nThe Classifier package handles supervised classification through traditional ML algorithms running in the Earth Engine. These classifiers include CART, RandomForest, NaiveBayes, and SVM.\n\n7.1.1 Classification and Regression Trees (CART)- ee.Classifier.smileCart\nA classification and regression tree (CART) is a predictive model that explains how to predict the value of an outcome variable based on other values.The output of a CART is a decision tree in which each fork is a partition of the predictor variable and each end node contains a prediction for the outcome variable.\n\n\n\nThe general workflow for classification. Source: https://bikeshbade.com.np/tutorials/Detail/?title=Supervised%20Classification%20in%20GEE&code=20.\n\n\nBasically, a decision tree is a fairly simple structure consisting of three different types of elements: a root node, which is the starting point containing all the training samples; multiple decision nodes, where we split the data using simple if-else decision rules, and multiple terminal nodes, where we end up assigning categories for classification purposes.\n\n\n\nDecision Tree Example. Source: https://blogs.fu-berlin.de/reseda/random-forest.\n\n\n\n7.1.1.1 Advantages and limitations\nAdvantages of Decision Trees:\n\nThe concept is fairly easy to understand compared to other classification algorithms.\nDecision trees can be visualised to help understand or explain it.\nIt can handle not only numerical data but also categorical data.\n\nDisadvantages of Decision Trees:\n\nProne to overfitting, which means creating extremely complex trees that don’t generalise the data correctly.\n\n\n\n\n7.1.2 Random Forest - ee.Classifier.smileRandomForest\nRandom Forest is a supervised learning algorithm which can be used for classification and regression. It is widely used in machine learning and constructs integrated classifiers by combining multiple CART trees.\nRandom forest creates decision trees on randomly selected data samples, obtains predictions from each tree and selects the best solution by voting.\n\n\n\n\n\n\n\n\nThe example of classification. Source: NASA’s Applied Remote Sensing Training Program.\n\n\n\n7.1.2.1 Advantages and limitations\nAdvantages:\n\nUse of multiple trees reduces the risk of overfitting.\nTraining time is shorter and not sensitive to outliers in training data.\nRuns efficiently and produces high accuracy for large datasets.\nEasy to parameterize.\n\nLimitations:\n\nAlgorithm cannot predict spectral range beyond training data.\nTraining data must capture the entire spectral range.\n\n\n\n\nSimple random forest classification completed for the San Francisco Bay Area of California in the GEE interface. Source: https://developers.google.com/earth-engine/guides/classification."
  },
  {
    "objectID": "week7.html#applications",
    "href": "week7.html#applications",
    "title": "7  Week7 Classification I",
    "section": "7.2 Applications",
    "text": "7.2 Applications\nWhile writing the above summary, I have been carrying a question: who is better among these classification methods? After searching the relevant literature with this given question, I found that there have actually been many studies on how CART, RS and SVM compare to each other, and even how they can be improved. Especially it has been mentioned and used in exploring land cover.\nZhao et al. (2024) showed that all three models performed well in LULC’s with reliable closure correlation accuracy and mapped to detect different classes of LULC’s during the classification process in the GEE platform.However, if we had to rank them: the Kappa coefficients of the CART, SVM, and RF were 94%, 95%, and 97%, respectively, while the average overall accuracy is 96.25%, 97% and 98.68%, respectively.The superior performance of the RF method in classification can be attributed to the larger size of the training dataset, which improves the classification accuracy.\nTheir findings are similar to those of Loukika et al. (2021) and Ouma et al. (2022) in that CART and SVM performed well in detecting and mapping water bodies in the study area; and RF and CART classifiers performed well in mapping built-up categories in the study area, whereas SVM confused them with bare soil.\nMy understanding is that who performs better depends on what data is used to classify, because models perform differently for different types, and only when data and methods match each other can we get better results. For example, a large number of studies have shown that RF is considered to be the most suitable algorithm for vegetation extraction in the current research field, followed by SVM; CART and SVM perform better for water classification.\n\n\n\na, Normalised Vegetation Index Difference (NVID). b, Corrected Normalised Difference Water Index (NDWI). c, Built-in indexes. d, L and land cover (LULC) maps of the study area using CART. e, Support Vector Machine (SVM) LULC maps. f, Random Forest Generated (RFG) LULC map. (Zhao et al. 2024)"
  },
  {
    "objectID": "week7.html#reflections",
    "href": "week7.html#reflections",
    "title": "7  Week7 Classification I",
    "section": "7.3 Reflections",
    "text": "7.3 Reflections\nI have been learning classification methods like Random Forests since my undergraduate degree, but was limited to solving simple classification projects in R. Until I walked into the Machine Learning area of GEE this week, I was happy that the methods I had been learning could be applied to new areas and solve more complex geographic problems.\nI recognised the importance of combining CART, RF and SVM models with geospatial techniques for LULC analysis because of their ability to accurately classify and predict land cover classes, detect changes over time and provide valuable insights for land management, environmental monitoring and urban planning.\nHowever, interpreting the output of a decision tree classifier or random forest is not as simple as reading coefficients and intercepts directly from a linear regression model as applied from CASA0007."
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "8  Week8 Classification II",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 How to consider / process EO data？\n\n8.1.1.1 Object-based Image Analysis\nIt is a method for classifying satellite imagery by segmenting neighboring pixels into objects using pre-segmented objects, it works opposite to pixel analysis.\nTraditional pixel based image classification assigns a land cover category to each pixel. All pixels have the same size, the same shape and do not have any notion of neighbours. However, OBIA segments images into small pixels that form vector objects. The segmentation is not based on each pixel, but automatically digitises the image for you.\n\n\n8.1.1.2 Sub-pixel Analysis\nIt is pixel-based image classification. A sub-pixel is a virtual pixel defined between two actual pixels in an image capture sensor. To improve the resolution or image quality, sub-pixel calculation is very useful. We can infer a more accurate object location in terms of sub-pixel resolution, i.e. the accuracy is higher than that of the pixel width and is a fraction of the pixel size with non-integer coordinates. It is also suitable for detecting objects smaller than pixel size.\n\n\n\n8.1.2 How to access the accuracy?\nAccuracy defines a measure of the clarity or certainty of a measurement. In remote sensing, we focus on the following accuracy values:\n\n8.1.2.1 User’s accuracy\nUA calculates the probability that a spatial data unit classified on a map or image actually represents a specific category on the ground. It can be referred to as reliability. The formula is as follows:\n\\(User's Accuracy=\\frac{Ture Positive}{Ture Positive + False Positive}\\)\n\n\n8.1.2.2 Producer’s accuracy\nPA is calculated in a similar way to UA, the only difference being that it calculates the ratio of the total number of pixels in which the category is correctly classified to the total number of pixels in that category in the classification map. The formula is as follows:\n\\(Producer's Accuracy=\\frac{Ture Positive}{Ture Positive+False Negative}\\)\n\n\n8.1.2.3 Kappa\nKappa is a measure of the difference between the observed agreement between two maps as reported by the diagonal entries in the error matrix. Expresses the accuracy of the image compared to chance results, which ranges from 0 to 1, with the following formula:\n\\(Kappa =\\frac{Total Accuracy – Random Accuracy}{1- Random Accuracy}\\)\nOne of the advantages of using this approach is that we can statistically compare two categorised products. For example, two classification maps can be produced using different algorithms and we can validate them using the same reference data.\nIt is used to compare two error matrices; to weight the cells in the error matrix according to the severity of misclassification; and to provide error ranges for accuracy.\n\n\n8.1.2.4 F1-Score (or F Measure)\nIt is a combination of UA and PA and is a measure of predictive performance. The formula is as follows:\n\\(F1 =\\frac{2*User’s Accuracy*Producer’s Accuracy}{User’s Accuracy+Producer’s Accuracy}\\)\nThe highest possible value of 1.0 for the F-score indicates perfect precision and recall; if precision or recall is zero, the lowest possible value is zero. ## Applications\n\n\n\nShows the different sources of errors that occur in classification. Source: https://www.researchgate.net/figure/23738314_fig2_Figure-2-Error-sources-and-accumulation-of-error-in-a-typical-remote-sensing-information."
  },
  {
    "objectID": "week8.html#applications",
    "href": "week8.html#applications",
    "title": "8  Week8 Classification II",
    "section": "8.2 Applications",
    "text": "8.2 Applications\nPolicymakers need timely and accurate information on landslides in order to respond effectively and quickly to disasters triggered by the same earthquake or rainfall. Remote sensing technologies can provide rapid disaster response at local to regional scales, especially in remote, isolated and inaccessible locations. These techniques are categorised into pixel-based, sub-pixel-based and object-based techniques, each with their own advantages and disadvantages.\nSaba et al. (2023) used all three of these methods for the detection of co-seismic landslides in Muzaffarabad (Little Himalayas), Pakistan. Ultimately, it was found that all three techniques can automatically detect co-seismic landslides with different levels of accuracy and associated limitations.\nThe pixel-based MLC classification system identified the least number of landslides, but with the worst results and accuracy, which is in line with the study of Martha et al. (2010), both suggesting that landslides are much more similar to other geographic entities in the spectrum, thus making it difficult to avoid spectral overlap effects.\nThe OBIA technique will produce good results, but only if fine spatial resolution images are used, which makes the technique somewhat expensive. COSI-Corr produces better results because landslide detection becomes more robust once the changing pixels are identified, using spectral information. The advantage is that it works at the sub-pixel level, eliminating the interference caused by mixed pixels. On the other hand, it utilises temporal changes to identify newly triggered co-seismic or active landslides more effectively than OBIA. The COSI-Corr-based technique is more suitable and cost-effective for detecting co-seismic landslides than MLC and OBIA.\n\n\n\nComparison of pixel, sub-pixel and object-based image analysis techniques for co-seismic landslides detection in seismically active area in Lesser Himalaya, Pakistan. Results from all the three classification techniques (yellow), i.e. a Pixel-based MLC, b Object–based and c COSI-Corr, are overlain by manually prepared landslide inventory polygons (red). Source: https://doi.org/10.1007/s11069-022-05642-y."
  },
  {
    "objectID": "week8.html#reflections",
    "href": "week8.html#reflections",
    "title": "8  Week8 Classification II",
    "section": "8.3 Reflections",
    "text": "8.3 Reflections\nThis would be my first exposure to subpixel analysis for learning, and I was intrigued by the technique’s ability to recognise multiple feature information within a single pixel. This method is particularly suitable for dealing with scenes that have poorly defined feature boundaries or severe mixed-pixel problems, and greatly improves the ability to parse remotely sensed images.\nOverall, these learning experiences have not only enhanced my technical skills in remote sensing, but also stimulated me to think broadly about the future of remote sensing applications. I look forward to applying this knowledge to practical projects to solve more complex geographic and environmental problems."
  },
  {
    "objectID": "week7.html#references",
    "href": "week7.html#references",
    "title": "7  Week7 Classification I",
    "section": "7.4 References",
    "text": "7.4 References\nLoukika, K. N., Keesara, V. R. and Sridhar, V. (2021). ‘Analysis of Land Use and Land Cover Using Machine Learning Algorithms on Google Earth Engine for Munneru River Basin, India’. Sustainability. Multidisciplinary Digital Publishing Institute, 13 (24), p. 13758. https://doi.org/10.3390/su132413758\nOuma, Y., Nkwae, B., Moalafhi, D., Odirile, P., Parida, B., Anderson, G. and Qi, J. (2022). ‘COMPARISON OF MACHINE LEARNING CLASSIFIERS FOR MULTITEMPORAL AND MULTISENSOR MAPPING OF URBAN LULC FEATURES’. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences. XXIV ISPRS Congress “Imaging today, foreseeing tomorrow”, Commission III - 2022 edition, 6–11 June 2022, Nice, France, Copernicus GmbH, XLIII-B3-2022, pp. 681–689. https://doi.org/10.5194/isprs-archives-XLIII-B3-2022-681-2022\nZhao, Z., Islam, F., Waseem, L. A., Tariq, A., Nawaz, M., Islam, I. U., Bibi, T., Rehman, N. U., Ahmad, W., Aslam, R. W., Raza, D. and Hatamleh, W. A. (2024). ‘Comparison of Three Machine Learning Algorithms Using Google Earth Engine for Land Use Land Cover Classification’. Rangeland Ecology & Management, 92, pp. 129–137. https://doi.org/10.1016/j.rama.2023.10.007"
  },
  {
    "objectID": "week8.html#references",
    "href": "week8.html#references",
    "title": "8  Week8 Classification II",
    "section": "8.4 References",
    "text": "8.4 References\nCharacterising spectral, spatial and morphometric properties of landslides for semi-automatic detection using object-oriented methods’. Geomorphology, 116 (1), pp. 24–36. doi: 10.1016/j.geomorph.2009.10.004.\nSaba, S. B., Ali, M., Turab, S. A., Waseem, M. and Faisal, S. (2023). ‘Comparison of pixel, sub-pixel and object-based image analysis techniques for co-seismic landslides detection in seismically active area in Lesser Himalaya, Pakistan’. Natural Hazards, 115 (3), pp. 2383–2398. doi: 10.1007/s11069-022-05642-y."
  },
  {
    "objectID": "week6.html#references",
    "href": "week6.html#references",
    "title": "6  Week6 Google Earth Engine",
    "section": "6.4 References",
    "text": "6.4 References\nGomes, V.C., Queiroz, G.R. and Ferreira, K.R., 2020. An overview of platforms for big earth observation data management and analysis. Remote Sensing, 12(8), p.1253. doi: 10.3390/rs12081253.\nHussain, S., Mubeen, M., Ahmad, A., Akram, W., Hammad, H. M., Ali, M., Masood, N., Amin, A., Farid, H. U., Sultana, S. R., Fahad, S., Wang, D. and Nasim, W. (2020). ‘Using GIS tools to detect the land use/land cover changes during forty years in Lodhran District of Pakistan’. Environmental Science and Pollution Research, 27 (32), pp. 39676–39692. doi: 10.1007/s11356-019-06072-3.\nZheng, Y. and Zhu, Z. (2017). ‘Mapping major land cover dynamics in Beijing using all Landsat images in Google Earth Engine’. Remote Sensing of Environment, 202, pp. 166–176. doi: 10.1016/j.rse.2017.02.021."
  },
  {
    "objectID": "intro.html#here-is-xiaoyun-gong.",
    "href": "intro.html#here-is-xiaoyun-gong.",
    "title": "1  Hello",
    "section": "1.1 Here is Xiaoyun Gong.",
    "text": "1.1 Here is Xiaoyun Gong.\nThis is a book created from markdown and executable code."
  },
  {
    "objectID": "intro.html#if-you-find-that-some-pages-are-blank-click-refresh-or-something-else-in-the-menu-bar-and-then-return-to-view-them.",
    "href": "intro.html#if-you-find-that-some-pages-are-blank-click-refresh-or-something-else-in-the-menu-bar-and-then-return-to-view-them.",
    "title": "1  Hello",
    "section": "1.2 If you find that some pages are blank, click Refresh or something else in the menu bar and then return to view them.",
    "text": "1.2 If you find that some pages are blank, click Refresh or something else in the menu bar and then return to view them."
  },
  {
    "objectID": "intro.html#please-note",
    "href": "intro.html#please-note",
    "title": "1  Hello",
    "section": "1.2 Please note:",
    "text": "1.2 Please note:\nIf you find that some pages are blank, click Refresh or something else in the menu bar and then return to view them."
  },
  {
    "objectID": "week9.html#summary",
    "href": "week9.html#summary",
    "title": "9  Week 9 Temperature or SAR",
    "section": "9.1 Summary",
    "text": "9.1 Summary"
  },
  {
    "objectID": "week9.html#applications",
    "href": "week9.html#applications",
    "title": "9  Week 9 Temperature or SAR",
    "section": "9.2 Applications",
    "text": "9.2 Applications"
  },
  {
    "objectID": "week9.html#reflections",
    "href": "week9.html#reflections",
    "title": "9  Week 9 Temperature or SAR",
    "section": "9.3 Reflections",
    "text": "9.3 Reflections"
  },
  {
    "objectID": "week9.html#references",
    "href": "week9.html#references",
    "title": "9  Week 9 Temperature or SAR",
    "section": "9.4 References",
    "text": "9.4 References"
  },
  {
    "objectID": "week4.html#references",
    "href": "week4.html#references",
    "title": "5  Week4 Policy：Flood management policy - San José",
    "section": "5.4 References",
    "text": "5.4 References\nArciniega-Esparza, S., Birkel, C., Chavarría-Palma, A., Arheimer, B. and Breña-Naranjo, J. A. (2022). ‘Remote sensing-aided rainfall–runoff modeling in the tropics of Costa Rica’. Hydrology and Earth System Sciences. Copernicus GmbH, 26 (4), pp. 975–999. doi: 10.5194/hess-26-975-2022.\nEkeu-wei, I. T. and Blackburn, G. A. (2018). ‘Applications of Open-Access Remotely Sensed Data for Flood Modelling and Mapping in Developing Regions’. Hydrology. Multidisciplinary Digital Publishing Institute, 5 (3), p. 39. doi: 10.3390/hydrology5030039."
  },
  {
    "objectID": "week3.html#references",
    "href": "week3.html#references",
    "title": "4  Week3 Corrections",
    "section": "4.4 References",
    "text": "4.4 References\nIlori, C. O., Pahlevan, N. and Knudby, A. (2019). ‘Analyzing Performances of Different Atmospheric Correction Techniques for Landsat 8: Application for Coastal Remote Sensing’. Remote Sensing. Multidisciplinary Digital Publishing Institute, 11 (4), p. 469. doi: 10.3390/rs11040469.\nShanmugam, P. and Ahn, Y.H., 2007. New atmospheric correction technique to retrieve the ocean colour from SeaWiFS imagery in complex coastal waters. Journal of Optics A: Pure and Applied Optics, 9(5), p.511. doi: 10.1088/1464-4258/9/5/016.\nWang, Y., Wang, X., He, H. and Tian, G. (2019). ‘An Improved Dark Object Subtraction Method for Atmospheric Correction of Remote Sensing Images’. in Wang, Yongtian, Huang, Q., and Peng, Y. (eds) Image and Graphics Technologies and Applications. Singapore: Springer (Communications in Computer and Information Science), pp. 425–435. doi: 10.1007/978-981-13-9917-6_41."
  }
]